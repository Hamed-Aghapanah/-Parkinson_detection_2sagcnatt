{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dwiuI7pedVzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "rwUrefn04Vjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Use CUDA:', torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bx-2j-X4XC4",
        "outputId": "ba1d9773-52d7-4de4-9de8-03bc945b362a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use CUDA: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.use_deterministic_algorithms = True"
      ],
      "metadata": {
        "id": "nlsCRsXu4ZAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape_instance(ins):\n",
        "  _,size,_,_=ins.shape        #?\n",
        "  return ins.reshape(3,size,25)\n"
      ],
      "metadata": {
        "id": "WixQu-kpLiWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_clip(data , length=300):\n",
        "  for item_iter in range(len(data)):\n",
        "    if data[item_iter].shape[1]>length:\n",
        "      data[item_iter]= data[item_iter][:,:length,:] #?\n",
        "  return data"
      ],
      "metadata": {
        "id": "GuELNH8H5lJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Dataset pickles"
      ],
      "metadata": {
        "id": "TAYeKd9fzZju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Park/train_3d.pkl', 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "    # train_label = [int(i['label']/10) for i in train_data]\n",
        "    train_label = [i['label'] for i in train_data]\n",
        "    print(train_label[:10])\n",
        "    train_data = [reshape_instance(i['keypoint']) for i in train_data]\n",
        "\n",
        "with open('/content/drive/MyDrive/Park/test_3d.pkl', 'rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "    # test_label = [int(i['label']/10) for i in test_data]\n",
        "    test_label = [i['label'] for i in test_data]\n",
        "    print(test_label[:10])\n",
        "    test_data = [reshape_instance(i['keypoint']) for i in test_data]\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Park/val_3d.pkl', 'rb') as f:\n",
        "    val_data = pickle.load(f)\n",
        "    # val_label = [int(i['label']/10) for i in val_data]\n",
        "    val_label = [i['label'] for i in val_data]\n",
        "    print(val_label[:10])\n",
        "    val_data = [reshape_instance(i['keypoint']) for i in val_data]\n",
        "\n",
        "train_data = crop_clip(train_data)\n",
        "test_data = crop_clip(test_data)\n",
        "val_data = crop_clip(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7lc0LCAGzFr",
        "outputId": "b7dcbb20-28ec-44cb-b47e-f9dd37fe404b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[71, 24, 87, 93, 69, 51, 21, 79, 36, 79]\n",
            "[21, 63, 87, 1, 2, 59, 30, 16, 8, 26]\n",
            "[5, 9, 52, 93, 4, 71, 59, 13, 7, 87]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(train_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQbp4QbOJtmd",
        "outputId": "7ce82718-69f9-4b9b-de62-ddaac55418ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining collator and feeder"
      ],
      "metadata": {
        "id": "YrzO20amz8th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "class MyCollator(object):   #?\n",
        "    def __init__(self,test=False,percentile=4750):\n",
        "        self.test = test\n",
        "        self.percentile = percentile\n",
        "    def __call__(self, batch):\n",
        "        # data = [torch.Tensor(item[0]) for item in batch]\n",
        "\n",
        "\n",
        "\n",
        "        # data = pad_sequence(data, padding_value=0)\n",
        "        # target = pad_sequence(target, padding_value=0)\n",
        "        # target = torch.Tensor(target)\n",
        "        # for items in batch:\n",
        "        #   if items[0].shape[1]>300:\n",
        "        #     items[0]= items[0][:,:300,:,:]\n",
        "        max_len = 300\n",
        "        max_len2 = max([x[0].shape[2] for x in batch])\n",
        "\n",
        "        # return [data, target]\n",
        "        batch = sorted(batch, key=lambda x: x[0].shape[1], reverse=True)\n",
        "        target = [item[1] for item in batch]\n",
        "        data = [torch.Tensor(item[0]) for item in batch]\n",
        "        # Pad the sequences to the length of the longest sequence in the batch\n",
        "        # padded_batch = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "        padded_batch = [torch.nn.functional.pad(torch.Tensor(gif[0]), ( 0,0,max_len - gif[0].shape[1], 0)) for gif in batch]\n",
        "        # stack = [[seq[i],label[i]] for i in range(padded_batch.shape[0])]\n",
        "\n",
        "        return [torch.stack(padded_batch),target]\n",
        "\n",
        "class MyCollator_backup(object):\n",
        "    def __init__(self,test=False,percentile=4750):\n",
        "        self.test = test\n",
        "        self.percentile = percentile\n",
        "    def __call__(self, batch):\n",
        "        # data = [torch.Tensor(item[0]) for item in batch]\n",
        "\n",
        "\n",
        "\n",
        "        # data = pad_sequence(data, padding_value=0)\n",
        "        # target = pad_sequence(target, padding_value=0)\n",
        "        # target = torch.Tensor(target)\n",
        "        max_len = max([x[0].shape[1] for x in batch])\n",
        "        max_len2 = max([x[0].shape[2] for x in batch])\n",
        "\n",
        "        # return [data, target]\n",
        "        batch = sorted(batch, key=lambda x: x[0].shape[1], reverse=True)\n",
        "        target = [item[1] for item in batch]\n",
        "        data = [torch.Tensor(item[0]) for item in batch]\n",
        "        # Pad the sequences to the length of the longest sequence in the batch\n",
        "        # padded_batch = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "        padded_batch = [torch.nn.functional.pad(torch.Tensor(gif[0]), ( 0,0,max_len - gif[0].shape[1], 0)) for gif in batch]\n",
        "        # stack = [[seq[i],label[i]] for i in range(padded_batch.shape[0])]\n",
        "\n",
        "        return [torch.stack(padded_batch),target]\n",
        "\n",
        "# def pad_collate(batch):\n",
        "#   data = [item[0] for item in batch]\n",
        "#         target = [item[1] for item in batch]\n",
        "#         target = torch.LongTensor(target)\n",
        "\n",
        "#   xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
        "#   yy_pad = pad_sequence(yy, batch_first=True, padding_value=0)\n",
        "\n",
        "#   return xx_pad, yy_pad, x_lens, y_lens\n"
      ],
      "metadata": {
        "id": "u0me7XrAgq1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Feeder(torch.utils.data.Dataset):\n",
        "  def __init__(self, data, label):\n",
        "      super().__init__()\n",
        "      self.label = label\n",
        "      self.data = data\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.label)\n",
        "\n",
        "  def __iter__(self):\n",
        "      return self\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      data = np.array(self.data[index])\n",
        "      label = self.label[index]\n",
        "\n",
        "      return data, label"
      ],
      "metadata": {
        "id": "Asb7794y4dys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Graph to load data in the way ntu+rgb D models give it to action recongnition model"
      ],
      "metadata": {
        "id": "WOpHygT-zq-T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFV6MAuFds7V"
      },
      "outputs": [],
      "source": [
        "class Graph():\n",
        "  def __init__(self, hop_size, strategy):\n",
        "    self.get_edge()\n",
        "\n",
        "    self.hop_size = hop_size\n",
        "    self.hop_dis = self.get_hop_distance(self.num_node, self.edge, hop_size=hop_size)\n",
        "\n",
        "    self.get_adjacency(strategy)\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.A\n",
        "\n",
        "  def get_edge(self):\n",
        "    self.num_node = 25\n",
        "    self_link = [(i, i) for i in range(self.num_node)]\n",
        "    neighbor_base = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21),\n",
        "                      (6, 5), (7, 6), (8, 7), (9, 21), (10, 9),\n",
        "                      (11, 10), (12, 11), (13, 1), (14, 13), (15, 14),\n",
        "                      (16, 15), (17, 1), (18, 17), (19, 18), (20, 19),\n",
        "                      (22, 23), (23, 8), (24, 25), (25, 12)]\n",
        "    neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_base]\n",
        "    self.self_link = self_link\n",
        "    self.neighbor_link = neighbor_link\n",
        "    self.edge = self_link + neighbor_link\n",
        "    self.center = 21 - 1     #?\n",
        "\n",
        "  def get_adjacency(self, strategy):\n",
        "    valid_hop = range(0, self.hop_size + 1, 1)\n",
        "    adjacency = np.zeros((self.num_node, self.num_node))\n",
        "    for hop in valid_hop:\n",
        "        adjacency[self.hop_dis == hop] = 1\n",
        "    normalize_adjacency = self.normalize_digraph(adjacency)\n",
        "    if strategy == 'spatial':\n",
        "      A = []\n",
        "      for hop in valid_hop:\n",
        "          a_root = np.zeros((self.num_node, self.num_node))\n",
        "          a_close = np.zeros((self.num_node, self.num_node))\n",
        "          a_further = np.zeros((self.num_node, self.num_node))\n",
        "          for i in range(self.num_node):\n",
        "              for j in range(self.num_node):\n",
        "                  if self.hop_dis[j, i] == hop:\n",
        "                      if self.hop_dis[j, self.center] == self.hop_dis[\n",
        "                              i, self.center]:\n",
        "                          a_root[j, i] = normalize_adjacency[j, i]\n",
        "                      elif self.hop_dis[j, self.center] > self.hop_dis[\n",
        "                              i, self.center]:\n",
        "                          a_close[j, i] = normalize_adjacency[j, i]\n",
        "                      else:\n",
        "                          a_further[j, i] = normalize_adjacency[j, i]\n",
        "          if hop == 0:\n",
        "              A.append(a_root)\n",
        "          else:\n",
        "              A.append(a_root + a_close)\n",
        "              A.append(a_further)\n",
        "      A = np.stack(A)\n",
        "      self.A = A\n",
        "    elif strategy == 'agcn':\n",
        "      A = []\n",
        "      link_mat = self.edge2mat(self.self_link, self.num_node)\n",
        "      In = self.normalize_digraph(self.edge2mat(self.neighbor_link, self.num_node))\n",
        "      outward = [(j, i) for (i, j) in self.neighbor_link]\n",
        "      Out = self.normalize_digraph(self.edge2mat(outward, self.num_node))\n",
        "      A = np.stack((link_mat, In, Out))\n",
        "      self.A = A\n",
        "    else:\n",
        "        raise ValueError('Do Not Exist This Strategy')\n",
        "\n",
        "  def get_hop_distance(self, num_node, edge, hop_size):\n",
        "    A = np.zeros((num_node, num_node))\n",
        "    for i, j in edge:\n",
        "        A[j, i] = 1\n",
        "        A[i, j] = 1\n",
        "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
        "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(hop_size + 1)]\n",
        "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
        "    for d in range(hop_size, -1, -1):\n",
        "        hop_dis[arrive_mat[d]] = d\n",
        "    return hop_dis\n",
        "\n",
        "  def normalize_digraph(self, A):\n",
        "    Dl = np.sum(A, 0)\n",
        "    num_node = A.shape[0]\n",
        "    Dn = np.zeros((num_node, num_node))\n",
        "    for i in range(num_node):\n",
        "        if Dl[i] > 0:\n",
        "            Dn[i, i] = Dl[i]**(-1)\n",
        "    DAD = np.dot(A, Dn)\n",
        "    return DAD\n",
        "\n",
        "  def edge2mat(self, link, num_node):\n",
        "    A = np.zeros((num_node, num_node))\n",
        "    for i, j in link:\n",
        "        A[j, i] = 1\n",
        "    return A"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention Module class"
      ],
      "metadata": {
        "id": "1mgKTu4wzOKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels // reduction),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_channels // reduction, in_channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y"
      ],
      "metadata": {
        "id": "BM7busvzzS7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STGCN Backbone"
      ],
      "metadata": {
        "id": "awGAgKJdy1EZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrffcNi0ZCP7"
      },
      "outputs": [],
      "source": [
        "class SpatialGraphConvolution(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, s_kernel_size):\n",
        "    super().__init__()\n",
        "    self.s_kernel_size = s_kernel_size\n",
        "    self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                          out_channels=out_channels * s_kernel_size,\n",
        "                          kernel_size=1)\n",
        "\n",
        "  def forward(self, x, A):\n",
        "    x = self.conv(x)\n",
        "    n, kc, t, v = x.size()\n",
        "    x = x.view(n, self.s_kernel_size, kc//self.s_kernel_size, t, v)\n",
        "    x = torch.einsum('nkctv,kvw->nctw', (x, A))\n",
        "    return x.contiguous()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class STGC_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride, t_kernel_size, A_size, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sgc = SpatialGraphConvolution(in_channels=in_channels,\n",
        "                                           out_channels=out_channels,\n",
        "                                           s_kernel_size=A_size[0])\n",
        "\n",
        "\n",
        "        self.M = nn.Parameter(torch.ones(A_size))\n",
        "\n",
        "        self.tgc = nn.Sequential(\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(out_channels,\n",
        "                      out_channels,\n",
        "                      (t_kernel_size, 1),\n",
        "                      (stride, 1),\n",
        "                      ((t_kernel_size - 1) // 2, 0)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Add channel attention\n",
        "        self.channel_attention = ChannelAttention(out_channels)\n",
        "\n",
        "    def forward(self, x, A):\n",
        "        x = self.tgc(self.sgc(x, A * self.M))\n",
        "\n",
        "        # Apply channel attention\n",
        "        x = self.channel_attention(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "rKArRPkkGjmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPcF2Od9AvmA"
      },
      "outputs": [],
      "source": [
        "# class STGC_block(nn.Module):\n",
        "#   def __init__(self, in_channels, out_channels, stride, t_kernel_size, A_size, dropout=0.5):\n",
        "#     super().__init__()\n",
        "\n",
        "#     self.sgc = SpatialGraphConvolution(in_channels=in_channels,\n",
        "#                                        out_channels=out_channels,\n",
        "#                                        s_kernel_size=A_size[0])\n",
        "\n",
        "#     self.M = nn.Parameter(torch.ones(A_size))\n",
        "\n",
        "#     self.tgc = nn.Sequential(nn.BatchNorm2d(out_channels),\n",
        "#                             nn.ReLU(),\n",
        "#                             nn.Dropout(dropout),\n",
        "#                             nn.Conv2d(out_channels,\n",
        "#                                       out_channels,\n",
        "#                                       (t_kernel_size, 1),\n",
        "#                                       (stride, 1),\n",
        "#                                       ((t_kernel_size - 1) // 2, 0)),\n",
        "#                             nn.BatchNorm2d(out_channels),\n",
        "#                             nn.ReLU())\n",
        "\n",
        "#   def forward(self, x, A):\n",
        "#     x = self.tgc(self.sgc(x, A * self.M))\n",
        "#     return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzAe1GgpZv7k"
      },
      "outputs": [],
      "source": [
        "class ST_GCN(nn.Module):\n",
        "  def __init__(self, num_classes, in_channels, t_kernel_size, hop_size):\n",
        "    super().__init__()\n",
        "    graph = Graph(hop_size)\n",
        "    A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
        "    self.register_buffer('A', A)\n",
        "    A_size = A.size()\n",
        "\n",
        "    # Batch Normalization\n",
        "    self.bn = nn.BatchNorm1d(in_channels * A_size[1])\n",
        "\n",
        "    # STGC_blocks\n",
        "    self.stgc1 = STGC_block(in_channels, 32, 1, t_kernel_size, A_size)\n",
        "    self.stgc2 = STGC_block(32, 32, 1, t_kernel_size, A_size)\n",
        "    self.stgc3 = STGC_block(32, 32, 1, t_kernel_size, A_size)\n",
        "    self.stgc4 = STGC_block(32, 64, 2, t_kernel_size, A_size)\n",
        "    self.stgc5 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n",
        "    self.stgc6 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n",
        "\n",
        "    # Prediction\n",
        "    self.fc = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Batch Normalization\n",
        "    N, C, T, V = x.size() # batch, channel, frame, node\n",
        "    x = x.permute(0, 3, 1, 2).contiguous().view(N, V * C, T)\n",
        "    x = self.bn(x)\n",
        "    x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()\n",
        "\n",
        "    # STGC_blocks\n",
        "    x = self.stgc1(x, self.A)\n",
        "    x = self.stgc2(x, self.A)\n",
        "    x = self.stgc3(x, self.A)\n",
        "    x = self.stgc4(x, self.A)\n",
        "    x = self.stgc5(x, self.A)\n",
        "    x = self.stgc6(x, self.A)\n",
        "\n",
        "    # Prediction\n",
        "    x = F.avg_pool2d(x, x.size()[2:])\n",
        "    x = x.view(N, -1, 1, 1)\n",
        "    x = self.fc(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AGCN Backbone"
      ],
      "metadata": {
        "id": "pIUDd5P007ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def kaiming_init(module: nn.Module,\n",
        "                 a: float = 0,\n",
        "                 mode: str = 'fan_out',\n",
        "                 nonlinearity: str = 'relu',\n",
        "                 bias: float = 0,\n",
        "                 distribution: str = 'normal') -> None:\n",
        "    assert distribution in ['uniform', 'normal']\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        if distribution == 'uniform':\n",
        "            nn.init.kaiming_uniform_(\n",
        "                module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n",
        "        else:\n",
        "            nn.init.kaiming_normal_(\n",
        "                module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)\n",
        "\n",
        "\n",
        "def constant_init(module: nn.Module, val: float, bias: float = 0) -> None:\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        nn.init.constant_(module.weight, val)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)\n",
        "\n",
        "\n",
        "def normal_init(module: nn.Module,\n",
        "                mean: float = 0,\n",
        "                std: float = 1,\n",
        "                bias: float = 0) -> None:\n",
        "    if hasattr(module, 'weight') and module.weight is not None:\n",
        "        nn.init.normal_(module.weight, mean, std)\n",
        "    if hasattr(module, 'bias') and module.bias is not None:\n",
        "        nn.init.constant_(module.bias, bias)\n",
        "\n",
        "\n",
        "\n",
        "def conv_branch_init(conv, branches):\n",
        "    weight = conv.weight\n",
        "    n = weight.size(0)\n",
        "    k1 = weight.size(1)\n",
        "    k2 = weight.size(2)\n",
        "    normal_init(weight, mean=0, std=math.sqrt(2. / (n * k1 * k2 * branches)))\n",
        "    constant_init(conv.bias, 0)\n",
        "\n",
        "def conv_init(conv):\n",
        "    kaiming_init(conv.weight)\n",
        "    constant_init(conv.bias, 0)\n",
        "\n",
        "def bn_init(bn, scale):\n",
        "    constant_init(bn.weight, scale)\n",
        "    constant_init(bn.bias, 0)\n",
        "\n",
        "\n",
        "def zero(x):\n",
        "    \"\"\"return zero.\"\"\"\n",
        "    return 0\n",
        "\n",
        "\n",
        "def identity(x):\n",
        "    \"\"\"return input itself.\"\"\"\n",
        "    return x"
      ],
      "metadata": {
        "id": "Ml0cq05z2rZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvTemporalGraphical(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 t_kernel_size=1,\n",
        "                 t_stride=1,\n",
        "                 t_padding=0,\n",
        "                 t_dilation=1,\n",
        "                 adj_len=25,\n",
        "                 bias=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        # 3 for 2sagcn 5 for stgcn\n",
        "        self.PA = nn.Parameter(torch.FloatTensor(3, adj_len, adj_len))\n",
        "        torch.nn.init.constant_(self.PA, 1e-6)\n",
        "\n",
        "        self.num_subset = 3\n",
        "        inter_channels = out_channels // 4\n",
        "        self.inter_c = inter_channels\n",
        "        self.conv_a = nn.ModuleList()\n",
        "        self.conv_b = nn.ModuleList()\n",
        "        self.conv_d = nn.ModuleList()\n",
        "        for i in range(self.num_subset):\n",
        "            self.conv_a.append(nn.Conv2d(in_channels, inter_channels, 1))\n",
        "            self.conv_b.append(nn.Conv2d(in_channels, inter_channels, 1))\n",
        "            self.conv_d.append(nn.Conv2d(in_channels, out_channels, 1))\n",
        "\n",
        "        if in_channels != out_channels:\n",
        "            self.down = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        else:\n",
        "            self.down = lambda x: x\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.soft = nn.Softmax(-2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                conv_init(m)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                bn_init(m, 1)\n",
        "        bn_init(self.bn, 1e-6)\n",
        "        for i in range(self.num_subset):\n",
        "            conv_branch_init(self.conv_d[i], self.num_subset)\n",
        "\n",
        "    def forward(self, x, adj_mat):\n",
        "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
        "        assert adj_mat.size(0) == self.kernel_size\n",
        "\n",
        "        N, C, T, V = x.size()\n",
        "        A = adj_mat + self.PA\n",
        "\n",
        "        y = None\n",
        "        for i in range(self.num_subset):\n",
        "            A1 = self.conv_a[i](x).permute(0, 3, 1, 2).contiguous().view(\n",
        "                N, V, self.inter_c * T)\n",
        "            A2 = self.conv_b[i](x).view(N, self.inter_c * T, V)\n",
        "            A1 = self.soft(torch.matmul(A1, A2) / A1.size(-1))  # N V V\n",
        "            A1 = A1 + A[i]\n",
        "            A2 = x.view(N, C * T, V)\n",
        "            z = self.conv_d[i](torch.matmul(A2, A1).view(N, C, T, V))\n",
        "            y = z + y if y is not None else z\n",
        "        y = self.bn(y)\n",
        "        y += self.down(x)\n",
        "\n",
        "        return self.relu(y), adj_mat"
      ],
      "metadata": {
        "id": "glRUWrqo2Aol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AGCNBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 adj_len=25,\n",
        "                 dropout=0,\n",
        "                 residual=True):\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(kernel_size) == 2\n",
        "        assert kernel_size[0] % 2 == 1\n",
        "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
        "\n",
        "        self.gcn = ConvTemporalGraphical(\n",
        "            in_channels, out_channels, kernel_size[1], adj_len=adj_len)\n",
        "        self.tcn = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, (kernel_size[0], 1),\n",
        "                      (stride, 1), padding), nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        # tcn init\n",
        "        for m in self.tcn.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                conv_init(m)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                bn_init(m, 1)\n",
        "\n",
        "        if not residual:\n",
        "            self.residual = zero\n",
        "\n",
        "        elif (in_channels == out_channels) and (stride == 1):\n",
        "            self.residual = identity\n",
        "\n",
        "        else:\n",
        "            self.residual = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_channels,\n",
        "                    out_channels,\n",
        "                    kernel_size=1,\n",
        "                    stride=(stride, 1)), nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # put list of attention here ['pam', 'cam']\n",
        "        self.att_type = []\n",
        "        self.attention = len(self.att_type)\n",
        "        if self.attention > 0:\n",
        "          self.channel_attention = ChannelAttention(out_channels)\n",
        "\n",
        "    def forward(self, x, adj_mat):\n",
        "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
        "        res = self.residual(x)\n",
        "        x, adj_mat = self.gcn(x, adj_mat)\n",
        "\n",
        "        if self.attention == 1 and self.att_type[0] == 'pam' :\n",
        "          x = self.channel_attention(x)\n",
        "          x = self.tcn(x)\n",
        "          x = x + res\n",
        "        elif self.attention == 1 and self.att_type[0] == 'cam':\n",
        "          x = self.tcn(x)\n",
        "          x = self.channel_attention(x)\n",
        "          x = x + res\n",
        "        else:\n",
        "          x = self.tcn(x) + res\n",
        "\n",
        "        if self.attention == 2:\n",
        "          x = self.channel_attention(x)\n",
        "\n",
        "        return self.relu(x), adj_mat"
      ],
      "metadata": {
        "id": "BQ-G5eZG1AsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AGCN(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 hop_size,\n",
        "                 strategy,\n",
        "                 pretrained=None,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        # load graph\n",
        "        self.graph = Graph(hop_size, strategy)\n",
        "        A = torch.tensor(\n",
        "            self.graph.A, dtype=torch.float32, requires_grad=False)\n",
        "        self.register_buffer('A', A)\n",
        "        A_size = A.size()\n",
        "\n",
        "        # build networks\n",
        "        spatial_kernel_size = A.size(0)\n",
        "        temporal_kernel_size = 9\n",
        "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
        "        self.bn = nn.BatchNorm1d(in_channels * A_size[1])\n",
        "\n",
        "\n",
        "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
        "        self.agcn_networks = nn.ModuleList((\n",
        "            AGCNBlock(\n",
        "                in_channels,\n",
        "                64,\n",
        "                kernel_size,\n",
        "                1,\n",
        "                adj_len=A.size(1),\n",
        "                residual=False,\n",
        "                **kwargs0),\n",
        "            AGCNBlock(64, 64, kernel_size, 1,adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(64, 64, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(64, 64, kernel_size, 1,adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(64, 128, kernel_size, 2, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(128, 128, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(128, 128, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(128, 256, kernel_size, 2, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(256, 256, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "            AGCNBlock(256, 256, kernel_size, 1, adj_len=A.size(1), **kwargs),\n",
        "        ))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Defines the computation performed at every call.\n",
        "        Args:\n",
        "            x (torch.Tensor): The input data.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output of the module.\n",
        "        \"\"\"\n",
        "        # data normalization\n",
        "        N, C, T, V = x.size() # batch, channel, frame, node\n",
        "        x = x.permute(0, 3, 1, 2).contiguous().view(N, V * C, T)\n",
        "        x = self.bn(x)\n",
        "        x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()\n",
        "\n",
        "        for gcn in self.agcn_networks:\n",
        "            x, _ = gcn(x, self.A)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "X_7A6mvy3xz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STGCN head"
      ],
      "metadata": {
        "id": "DuQ8KaTd7nMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class STGCNHead(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_classes,\n",
        "                 in_channels,\n",
        "                 loss_cls=dict(type='CrossEntropyLoss'),\n",
        "                 spatial_type='avg',\n",
        "                 num_person=1,\n",
        "                 init_std=0.01,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.spatial_type = spatial_type\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.num_person = num_person\n",
        "        self.init_std = init_std\n",
        "\n",
        "        self.pool = None\n",
        "        if self.spatial_type == 'avg':\n",
        "            self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        elif self.spatial_type == 'max':\n",
        "            self.pool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        self.fc = nn.Conv2d(self.in_channels, self.num_classes, kernel_size=1)\n",
        "\n",
        "    def init_weights(self):\n",
        "        normal_init(self.fc, std=self.init_std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # global pooling\n",
        "        assert self.pool is not None\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.shape[0] // self.num_person, self.num_person, -1, 1,\n",
        "                   1).mean(dim=1)\n",
        "\n",
        "        # prediction\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZQqsN6em7uvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Definition"
      ],
      "metadata": {
        "id": "GdchloFu-wwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### STGCN"
      ],
      "metadata": {
        "id": "a29cHE29-2Nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class STGCN(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_classes,\n",
        "               in_channels,\n",
        "               t_kernel_size,\n",
        "               hop_size,\n",
        "               strategy='spatial'):\n",
        "    super().__init__()\n",
        "\n",
        "    self.agcn = AGCN(in_channels, hop_size, strategy)\n",
        "    self.stgcnhead = STGCNHead(num_classes, in_channels=256)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.agcn(x)\n",
        "    x = self.stgcnhead(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "tZceALlx-95n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2SAGCN"
      ],
      "metadata": {
        "id": "eAxSLDaE-59l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TWO_SAGCN(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_classes,\n",
        "               in_channels,\n",
        "               t_kernel_size,\n",
        "               hop_size,\n",
        "               strategy='agcn'):\n",
        "    super().__init__()\n",
        "\n",
        "    self.agcn = AGCN(in_channels, hop_size, strategy)\n",
        "    self.stgcnhead = STGCNHead(num_classes, in_channels=256)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.agcn(x)\n",
        "    x = self.stgcnhead(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "dMXRr9IjBWLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "3Q3cw9wf0rEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "NUM_EPOCH = 80\n",
        "BATCH_SIZE = 32\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "if(torch.cuda.is_available()):\n",
        "  model = STGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=2).cuda()\n",
        "else:\n",
        "  model = STGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=2)\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "data_loader = dict()\n",
        "collator = MyCollator()\n",
        "data_loader['train'] = torch.utils.data.DataLoader(dataset=Feeder(data=train_data, label=train_label), batch_size=BATCH_SIZE, shuffle=True,collate_fn=collator)\n",
        "data_loader['valid'] = torch.utils.data.DataLoader(dataset=Feeder(data=val_data, label=val_label), batch_size=BATCH_SIZE, shuffle=True,collate_fn=collator)\n",
        "data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data=test_data, label=test_label), batch_size=BATCH_SIZE, shuffle=False,collate_fn=collator)\n",
        "\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(1, NUM_EPOCH+1):\n",
        "  correct_train = 0\n",
        "  sum_loss = 0\n",
        "  model.train()\n",
        "  for batch_idx, (data, label) in enumerate(data_loader['train']):\n",
        "    # print(data)\n",
        "    if(torch.cuda.is_available()):\n",
        "      data = data.cuda()\n",
        "      label = torch.LongTensor(label).cuda()\n",
        "    else:\n",
        "      data = data\n",
        "      label = torch.LongTensor(label)\n",
        "\n",
        "\n",
        "    output = model(data)\n",
        "    # print(len(output),len(label))\n",
        "    loss = criterion(output, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    sum_loss += loss.item()\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "    correct_train += (predict == label).sum().item()\n",
        "\n",
        "  model.eval()\n",
        "  val_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data, label in data_loader['valid']:\n",
        "          if(torch.cuda.is_available()):\n",
        "            data = data.cuda()\n",
        "            label = torch.LongTensor(label).cuda()\n",
        "          else:\n",
        "            data = data\n",
        "            label = torch.LongTensor(label)\n",
        "          outputs = model(data)\n",
        "          val_loss =criterion(outputs, label)\n",
        "\n",
        "          sum_loss += val_loss.item()\n",
        "          _, predict = torch.max(outputs.data, 1)\n",
        "          correct += (predict == label).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "  print('# Epoch: {} | Train Loss: {:.4f} | Train Accuracy: {:.4f} | Val loss: {:.4f} | Val Accuracy: {:.4f}'.format(epoch, sum_loss/len(data_loader['train'].dataset),(100. * correct_train / len(data_loader['train'].dataset)),val_loss/len(data_loader['valid'].dataset), (100. * correct / len(data_loader['valid'].dataset))))"
      ],
      "metadata": {
        "id": "WeJl8qaXZH6U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "dc4781fd-91aa-42b7-a0ae-92ab65d8b02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-e2a0e3387715>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;31m# print(len(output),len(label))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-9688fba7d641>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstgcnhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-bd3f0ac76219>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magcn_networks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-5620a4b60e64>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj_mat)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;34m\"\"\"Defines the computation performed at every call.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pam'\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-9bd303d41e8a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj_mat)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             A1 = self.conv_a[i](x).permute(0, 3, 1, 2).contiguous().view(\n\u001b[0m\u001b[1;32m     60\u001b[0m                 N, V, self.inter_c * T)\n\u001b[1;32m     61\u001b[0m             \u001b[0mA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minter_c\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of Model"
      ],
      "metadata": {
        "id": "UrWow-Hp0yFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "confusion_matrix = np.zeros((100, 100))\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (data, label) in enumerate(data_loader['test']):\n",
        "    if(torch.cuda.is_available()):\n",
        "      data = data.cuda()\n",
        "      label = torch.LongTensor(label).cuda()\n",
        "    else:\n",
        "      data = data\n",
        "      label = torch.LongTensor(label)\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "    correct += (predict == label).sum().item()\n",
        "\n",
        "    for l, p in zip(label.view(-1), predict.view(-1)):\n",
        "      confusion_matrix[l.long(), p.long()] += 1\n",
        "\n",
        "len_cm = len(confusion_matrix)\n",
        "for i in range(len_cm):\n",
        "    sum_cm = np.sum(confusion_matrix[i])\n",
        "    for j in range(len_cm):\n",
        "        confusion_matrix[i][j] = 100 * (confusion_matrix[i][j] / sum_cm)\n",
        "\n",
        "classes = np.unique(train_label,return_counts=False)\n",
        "plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion matrix')\n",
        "plt.tight_layout()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "plt.ylabel('True')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('# Test Accuracy: {:.3f}[%]'.format(100. * correct / len(data_loader['test'].dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "_ovKpsCn4l2M",
        "outputId": "0b3feae9-3a37-4dc9-fc2d-e36f25d6e701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-ec41cddacf3a>:26: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  confusion_matrix[i][j] = 100 * (confusion_matrix[i][j] / sum_cm)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Test Accuracy: 81.546[%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making onnx Models for graphical purpose"
      ],
      "metadata": {
        "id": "ppm-WdM1hlDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q onnx"
      ],
      "metadata": {
        "id": "Hl4TC-X4jJeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_names = [\"Skeleton\"]\n",
        "output_names = [\"Parkinson Prediction\"]\n",
        "\n",
        "stgcn_model = STGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=2)\n",
        "\n",
        "for data, label in data_loader['train']:\n",
        "  x = data\n",
        "  break\n",
        "\n",
        "torch.onnx.export(stgcn_model, x, \"stgcn_model.onnx\", input_names=input_names, output_names=output_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZeY9pPVhwLm",
        "outputId": "9b1405bb-3e43-47e2-b473-630d4a760c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-9bd303d41e8a>:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert adj_mat.size(0) == self.kernel_size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_names = [\"Skeleton\"]\n",
        "output_names = [\"Parkinson Prediction\"]\n",
        "\n",
        "two_sagcn_model = TWO_SAGCN(num_classes=99,\n",
        "                    in_channels=3,\n",
        "                    t_kernel_size=9,\n",
        "                    hop_size=2)\n",
        "\n",
        "for data, label in data_loader['train']:\n",
        "  x = data\n",
        "  break\n",
        "\n",
        "torch.onnx.export(two_sagcn_model, x, \"2sagcn_model.onnx\", input_names=input_names, output_names=output_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5iEn5HJiWgs",
        "outputId": "36d2a522-7d58-46db-ab3a-dedbd1b4748d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-9d11ec776356>:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  assert adj_mat.size(0) == self.kernel_size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NCnE9MJ4iXso"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "awGAgKJdy1EZ",
        "UrWow-Hp0yFM"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}